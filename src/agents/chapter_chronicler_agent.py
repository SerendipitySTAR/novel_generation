import os
import re
from typing import Optional, Dict, Any
from datetime import datetime, timezone
from dotenv import load_dotenv

from src.llm_abstraction.llm_client import LLMClient
from src.persistence.database_manager import DatabaseManager
from src.core.models import Chapter

class ChapterChroniclerAgent:
    def __init__(self, db_name: str = "novel_mvp.db"):
        try:
            self.llm_client = LLMClient()
        except ValueError as e:
            print(f"ChapterChroniclerAgent Error: LLMClient initialization failed. {e}")
            print("Please ensure OPENAI_API_KEY is set in your environment or .env file.")
            raise
        except Exception as e:
            print(f"ChapterChroniclerAgent Error: An unexpected error occurred during LLMClient initialization: {e}")
            raise
        self.db_manager = DatabaseManager(db_name=db_name)

    def _construct_prompt(self, chapter_brief: str, current_chapter_plot_summary: str, style_preferences: str) -> str:
        prompt = f"""You are a novelist writing a chapter. Adhere to the style: {style_preferences}.
        Chapter Brief (context, characters, lore):
        --- BEGIN CHAPTER BRIEF ---
        {chapter_brief}
        --- END CHAPTER BRIEF ---

        Specific Plot for THIS Chapter: {current_chapter_plot_summary}

        Your output MUST be structured with these exact headings on new lines:
        Title:
        [A compelling title for this chapter. Single line.]

        Content:
        [The full chapter text. Aim for 700-1000 words. Develop the 'Specific Plot for THIS Chapter'.]

        Summary:
        [A concise 2-3 sentence summary of THIS chapter's key events and outcomes.]

        Ensure "Title:", "Content:", and "Summary:" are on their own lines. Do not add any other text before "Title:", or after the "Summary:" text.
        """
        return prompt

    def _parse_llm_response(self, llm_response: str, novel_id: int, chapter_number: int) -> Optional[Dict[str, Any]]:
        try:
            title = f"Chapter {chapter_number} (Untitled)" # Default title
            content = "Content not generated by LLM." # Default content
            summary = "Summary not generated by LLM." # Default summary

            # Try to find Title:
            # Using ^ and $ with re.MULTILINE to ensure "Title:" is on its own line
            title_match = re.search(r"^Title:(.*?)$", llm_response, re.MULTILINE | re.IGNORECASE)
            if title_match:
                title = title_match.group(1).strip()
                if not title: title = f"Chapter {chapter_number} (Untitled)" # If title is empty after marker

            # Try to find Content: (everything between Content: and Summary:)
            # Using re.MULTILINE for ^Content: and ^Summary: to ensure they are at the start of a line
            content_match = re.search(r"^Content:(.*?)Summary:", llm_response, re.DOTALL | re.IGNORECASE | re.MULTILINE)
            if content_match:
                content = content_match.group(1).strip()
            else: # Fallback for content if Summary: is missing or Content: is last
                content_match_fallback = re.search(r"^Content:(.*)", llm_response, re.DOTALL | re.IGNORECASE | re.MULTILINE)
                if content_match_fallback:
                    content = content_match_fallback.group(1).strip()

            # Try to find Summary: (everything after Summary:)
            summary_match = re.search(r"^Summary:(.*)", llm_response, re.DOTALL | re.IGNORECASE | re.MULTILINE)
            if summary_match:
                summary = summary_match.group(1).strip()

            # If content is still the default placeholder AND the LLM response was not empty,
            # it means structured parsing failed. As a last resort, use the whole response as content,
            # after attempting to strip a found title.
            if content == "Content not generated by LLM." and llm_response.strip():
                print("ChapterChroniclerAgent: Warning - Structured parsing for Content/Summary failed. Using fallback for content.")
                response_remainder = llm_response
                if title_match and llm_response.strip().startswith(title_match.group(0).strip()):
                    # If title was found at the beginning, strip it and its marker line
                    response_remainder = llm_response[len(title_match.group(0)):].strip()

                # Remove "Content:" marker if it exists at the start of the remainder
                response_remainder = re.sub(r"^Content:\s*", "", response_remainder, flags=re.IGNORECASE | re.MULTILINE).strip()
                # Remove "Summary:" marker and its text if it exists at the end of the remainder
                response_remainder = re.sub(r"Summary:.*$", "", response_remainder, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE).strip()

                if response_remainder: # If anything is left, use it as content
                    content = response_remainder
                else: # If even this fails, content remains "Content not generated..."
                    print("ChapterChroniclerAgent: Error - Fallback content parsing also resulted in empty content.")
                    return None # Essential content is missing

            if not title and content == "Content not generated by LLM." and summary == "Summary not generated by LLM.":
                 print(f"ChapterChroniclerAgent: Error - Could not parse any key sections. Response (first 500 chars): {llm_response[:500]}")
                 return None

            return {
                "id": 0,
                "novel_id": novel_id,
                "chapter_number": chapter_number,
                "title": title,
                "content": content,
                "summary": summary,
                "creation_date": datetime.now(timezone.utc).isoformat()
            }
        except Exception as e:
            print(f"ChapterChroniclerAgent: Exception during LLM response parsing - {e}. Response (first 500 chars): {llm_response[:500]}")
            return None

    def generate_and_save_chapter(self, novel_id: int, chapter_number: int, chapter_brief: str,
                                  current_chapter_plot_summary: str, style_preferences: str) -> Optional[Chapter]:
        prompt = self._construct_prompt(chapter_brief, current_chapter_plot_summary, style_preferences)

        print(f"ChapterChroniclerAgent: Sending prompt for Chapter {chapter_number} to LLM.")
        try:
            llm_response_text = self.llm_client.generate_text(
                prompt=prompt,
                model_name="gpt-3.5-turbo",
                temperature=0.7,
                max_tokens=2000
            )
            print(f"ChapterChroniclerAgent: Received response from LLM for Chapter {chapter_number}.")
        except Exception as e:
            print(f"ChapterChroniclerAgent: Error during LLM call for Chapter {chapter_number} - {e}")
            return None

        if not llm_response_text:
            print(f"ChapterChroniclerAgent: LLM returned an empty response for Chapter {chapter_number}.")
            return None

        parsed_chapter_data = self._parse_llm_response(llm_response_text, novel_id, chapter_number)

        if parsed_chapter_data:
            try:
                new_chapter_id = self.db_manager.add_chapter(
                    novel_id=parsed_chapter_data['novel_id'],
                    chapter_number=parsed_chapter_data['chapter_number'],
                    title=parsed_chapter_data['title'],
                    content=parsed_chapter_data['content'],
                    summary=parsed_chapter_data['summary']
                )
                final_chapter_obj = Chapter(
                    id=new_chapter_id,
                    novel_id=parsed_chapter_data['novel_id'],
                    chapter_number=parsed_chapter_data['chapter_number'],
                    title=parsed_chapter_data['title'],
                    content=parsed_chapter_data['content'],
                    summary=parsed_chapter_data['summary'],
                    creation_date=parsed_chapter_data['creation_date']
                )
                print(f"Chapter '{final_chapter_obj['title']}' (Chapter {final_chapter_obj['chapter_number']}) saved with ID {new_chapter_id} for Novel ID {novel_id}.")
                return final_chapter_obj
            except Exception as e:
                print(f"ChapterChroniclerAgent: Error saving chapter {chapter_number} to database: {e}")
                return None
        else:
            print(f"ChapterChroniclerAgent: Failed to parse LLM response into Chapter {chapter_number}. Raw response snippet: {llm_response_text[:300]}")
            return None

if __name__ == "__main__":
    print("--- Testing ChapterChroniclerAgent (Live LLM Call) ---")
    load_dotenv()
    if not os.getenv("OPENAI_API_KEY") or "dummy" in os.getenv("OPENAI_API_KEY", "").lower():
        print("WARNING: A valid OpenAI API key is required for this test to properly interact with the LLM.")
        if "dummykey" in os.getenv("OPENAI_API_KEY",""):
             print("ERROR: Test cannot reliably proceed with a known dummy key pattern. Please set a real API key.")
             exit(1)

    test_sql_db_name = "test_live_chapter_agent_refined.db"
    if os.path.exists(test_sql_db_name):
        os.remove(test_sql_db_name)

    db_mngr = DatabaseManager(db_name=test_sql_db_name)
    novel_id_for_test = -1

    try:
        novel_id_for_test = db_mngr.add_novel(
            user_theme="A haunted library where books write their own stories, and a young librarian must uncover the library's oldest secret.",
            style_preferences="Gothic mystery with elements of magical realism, atmospheric, detailed descriptions, character-focused narrative."
        )
        print(f"Created Novel ID for testing: {novel_id_for_test}")

        sample_brief = f"""
Novel Theme: A haunted library where books write their own stories, and a young librarian must uncover the library's oldest secret.
Style: Gothic mystery with elements of magical realism, atmospheric, detailed descriptions, character-focused narrative.
Overall Outline: Elara, a new librarian, notices books changing. She investigates, discovering the library is sentient and powered by a trapped spirit. She must choose to free the spirit or preserve the library's magic.
Worldview: The Library of Alexandria was not destroyed but hidden, its consciousness growing over millennia. It manifests new wings, corridors, and books based on the collective unconscious. Its magic is subtle, usually.
Main Plot Arc: Discovery of changing books -> Investigation of library's hidden sections -> Encounter with manifestations of the library's consciousness -> Uncovering the trapped spirit's story -> Climax involving a choice that affects the library and Elara.
Previous Events: This is the first chapter. No prior events in this novel's timeline.
Focus Characters for this Chapter:
Character: Elara - Role: Protagonist. Description: Young, inquisitive, loves books more than people. Inherited the librarian post from a distant aunt. Skeptical but open-minded.
Relevant Lore and Context: The library is known as the "Whispering Athenaeum." Locals avoid it. Legends say it chooses its librarian.
"""
        chapter_plot_summary = "Elara arrives at the imposing, ancient library. She meets the only other staff member, the cryptic groundskeeper Mr. Hemlock. During her first night shift, she witnesses a book's title changing on its spine and then its content altering when she opens it."
        novel_style = "Gothic mystery, atmospheric, detailed descriptions, character-focused narrative, slow-burn suspense."
        target_chapter_number = 1

        agent = ChapterChroniclerAgent(db_name=test_sql_db_name)
        print("ChapterChroniclerAgent initialized for live test.")

        print(f"\nGenerating Chapter {target_chapter_number} for Novel ID {novel_id_for_test} (Live Call)...")
        generated_chapter = agent.generate_and_save_chapter(
            novel_id=novel_id_for_test,
            chapter_number=target_chapter_number,
            chapter_brief=sample_brief,
            current_chapter_plot_summary=chapter_plot_summary,
            style_preferences=novel_style
        )

        if generated_chapter:
            print("\n--- Generated Chapter ---")
            print(f"ID: {generated_chapter['id']}")
            print(f"Novel ID: {generated_chapter['novel_id']}")
            print(f"Chapter Number: {generated_chapter['chapter_number']}")
            print(f"Title: {generated_chapter['title']}")
            print(f"Content (first 300 chars): {generated_chapter['content'][:300]}...")
            print(f"Summary: {generated_chapter['summary']}")
            print(f"Creation Date: {generated_chapter['creation_date']}")

            assert generated_chapter['id'] != 0
            assert len(generated_chapter['title']) > 0
            assert len(generated_chapter['content']) > 100
            assert len(generated_chapter['summary']) > 10

            db_chapter = db_mngr.get_chapter_by_id(generated_chapter['id'])
            assert db_chapter is not None
            if db_chapter:
                assert db_chapter['title'] == generated_chapter['title']
            print("\nChapter successfully generated, saved, and minimally verified in DB.")
        else:
            print("\nChapter generation and saving FAILED. This might be due to API key issues or LLM problems.")
            assert generated_chapter is not None, "Chapter generation returned None."

    except ValueError as ve:
        print(f"Configuration or Input Error: {ve}")
    except Exception as e:
        print(f"An error occurred during agent testing: {e}")
        print("Ensure your OPENAI_API_KEY is correctly set and valid.")
    finally:
        if os.path.exists(test_sql_db_name):
            print(f"\nCleaning up test database: {test_sql_db_name}")
            os.remove(test_sql_db_name)
        else:
            print(f"\nTest database {test_sql_db_name} not found or already cleaned up.")

    print("\n--- ChapterChroniclerAgent (Live LLM Call) Test Finished ---")
